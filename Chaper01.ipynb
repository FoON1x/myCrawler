{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01bc981",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2c66e",
   "metadata": {},
   "source": [
    "## 获取并解析html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6ce9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "# urllib是Python内置的一个模块，用于处理URL请求\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "content = html.read()\n",
    "print(content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6675d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')  #这里可以不使用.read()\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac63f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "# 以下表示不同的方式访问同一个元素\n",
    "print(bs.html.body.h1) # type: ignore\n",
    "print(bs.body.h1) # type: ignore\n",
    "print(bs.html.h1) # type: ignore\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6bdccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当创建BeautifulSoup对象时，需要传递两个参数\n",
    "# 其中第一个参数是HTML文档的内容，第二个参数是解析器的类型\n",
    "# html.parser是Python内置的HTML解析器，无需安全，大部分情况下都可以使用\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05234947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A Useful Page</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>An Interesting Title</h1>\n",
       "<div>\n",
       "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 与html.parser相比，lxml解析器速度更快，功能更强大，但需要额外安装\n",
    "# lxml可以容忍并修正一些问题，如未闭合的标签等\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'lxml')\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4f478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head>\n",
       "<title>A Useful Page</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>An Interesting Title</h1>\n",
       "<div>\n",
       "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
       "</div>\n",
       "\n",
       "\n",
       "</body></html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 另一个常用的解析器是html5lib，它可以解析HTML5文档\n",
    "# 它的功能最强大，能够处理更加糟糕的html，但速度较慢，且需要额外安装\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html5lib')\n",
    "bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073b97d",
   "metadata": {},
   "source": [
    "## 异常处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d024cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen('http://pythonscraping.com/pages/page1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f38ad6",
   "metadata": {},
   "source": [
    "上面这行代码主要会发生两种异常：\n",
    "+ 网页在服务器上不存在（或者获取页面时出现异常）：返回HTTPError\n",
    "+ 服务器不存在：返回URLError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b794b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n",
      "<http.client.HTTPResponse object at 0x000001657A8ADF90>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://pythonscraping.com/pages/page111.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8815684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x000001657BC67D00>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:  \n",
    "    print('HTTPError')\n",
    "except URLError as e:   # 断开网络以测试URLError\n",
    "    print('URLError')\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric3\\AppData\\Local\\Temp\\ipykernel_17132\\305675772.py:1: DeprecationWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead. If you really were looking for a tag called nonExistentTag, use .find(\"nonExistentTag\")\n",
      "  print(bs.nonExistentTag)\n",
      "C:\\Users\\eric3\\AppData\\Local\\Temp\\ipykernel_17132\\305675772.py:2: DeprecationWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead. If you really were looking for a tag called nonExistentTag, use .find(\"nonExistentTag\")\n",
      "  print(bs.nonExistentTag.someTag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'someTag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(bs\u001b[38;5;241m.\u001b[39mnonExistentTag)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonExistentTag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msomeTag\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'someTag'"
     ]
    }
   ],
   "source": [
    "print(bs.nonExistentTag)    # 调用这个不存在的标签会返回None\n",
    "print(bs.nonExistentTag.someTag)    # 调用None的子标签则会出现异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161f3f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag was not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric3\\AppData\\Local\\Temp\\ipykernel_17132\\3870769108.py:3: DeprecationWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead. If you really were looking for a tag called nonExistentTag, use .find(\"nonExistentTag\")\n",
      "  badContent = bs.nonExistentTag.someTag # type: ignore\n"
     ]
    }
   ],
   "source": [
    "# 为了处理可能发生的两种异常，可分别对这两种异常进行检测\n",
    "try:\n",
    "    badContent = bs.nonExistentTag.someTag # type: ignore\n",
    "except AttributeError as e:\n",
    "    print('Tag was not found')\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print('Tag was not found')\n",
    "    else:\n",
    "        print(badContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fcecb8",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c247ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title could not found\n"
     ]
    }
   ],
   "source": [
    "# 整体代码可规范为如下：\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError, URLError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    # 处理获取html时的异常\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        return None\n",
    "\n",
    "    # 处理bs解析时的异常\n",
    "    try:\n",
    "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "        title = bs.body.h1 # type: ignore\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "url = 'http://pythonscraping.com/pages/page1.html'\n",
    "title = getTitle(url)\n",
    "if title == None:\n",
    "    print('Title could not found')\n",
    "else:\n",
    "    print(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycrawler (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
